{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Stats from Basketball-Reference.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Constants, Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "import google\n",
    "import random\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Pool\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "import gspread\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "import unidecode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_worksheet(spreadsheet_name, worksheet_name):\n",
    "  \n",
    "#   gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
    "  \n",
    "  scope = ['https://spreadsheets.google.com/feeds']\n",
    "    \n",
    "  credentials = ServiceAccountCredentials.from_json_keyfile_name('Data-35df9a696bc1.json', scope)\n",
    "  \n",
    "  gc = gspread.authorize(credentials)\n",
    "\n",
    "  spreadsheet = gc.open(spreadsheet_name)\n",
    "    \n",
    "  worksheet = spreadsheet.worksheet(worksheet_name)\n",
    "\n",
    "  rows = worksheet.get_all_values()\n",
    "\n",
    "  print('{num_rows} rows loaded.'.format(num_rows=len(rows)))\n",
    "\n",
    "  df = pd.DataFrame.from_records(rows)\n",
    "  \n",
    "  print(df.head(5))\n",
    "\n",
    "  return df\n",
    "        \n",
    "worksheet = load_worksheet('nba_players_sanitized', 'hof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanitize_list(raw_list):\n",
    "    # Remove accented (Spanish) characters.\n",
    "    sanitized_list = [unidecode.unidecode(accented_string) for accented_string in raw_list]\n",
    "    # Trim & lower-case\n",
    "    sanitized_list = [string.strip().lower() for string in sanitized_list]\n",
    "    # Remove quotes\n",
    "    sanitized_list = [string.replace(\"'\", \"\") for string in sanitized_list]\n",
    "    sanitized_list = [string.replace('\"', '') for string in sanitized_list]\n",
    "    # Remove dots\n",
    "    sanitized_list = [string.replace('.', '') for string in sanitized_list]\n",
    "    for i, string in enumerate(sanitized_list):\n",
    "        if \",\" in string:\n",
    "            lst = string.split(\",\")\n",
    "            lst.reverse()\n",
    "            lst = [token.strip() for token in lst]\n",
    "            sanitized_string = \" \".join(lst)\n",
    "            sanitized_list[i] = sanitized_string\n",
    "            \n",
    "    return sanitized_list\n",
    "\n",
    "sample_list = [\"Shaquille O'neal\", \"J. J. Reddick\", \"VinCe Carter \", \"Bryant, Kobe\"]\n",
    "\n",
    "print(sanitize_list(sample_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load Pickled Dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test = {\n",
    "    'words': \"\"\"\n",
    "        Lorem ipsum dolor sit amet, consectetur adipiscing \n",
    "        elit. Mauris adipiscing adipiscing placerat. \n",
    "        Vestibulum augue augue, \n",
    "        pellentesque quis sollicitudin id, adipiscing.\n",
    "        \"\"\",\n",
    "    'list': list(range(10000)),\n",
    "    'dict': dict((str(i),'a') for i in range(10000)),\n",
    "    'int': 100,\n",
    "    'float': 100.123456\n",
    "}\n",
    "\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "def get_file_size(filename):\n",
    "    statinfo = os.stat(filename)\n",
    "    return sizeof_fmt(statinfo.st_size)\n",
    "\n",
    "def save_dict(dictionary, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(dictionary, file)\n",
    "    print('\\n', 'file size: ', get_file_size(filename))\n",
    "    return True;\n",
    "\n",
    "def load_dict(filename):\n",
    "    print('\\n', 'file size: ', get_file_size(filename))\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "save_dict(test, 'test.pickle')\n",
    "\n",
    "len(load_dict('test.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define & Load Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Tables to retrieve for each player, by table html ids\n",
    "table_ids = [\n",
    "  'per_game',\n",
    "  'totals',\n",
    "  'per_minute', # per 36 minutes\n",
    "  'per_poss', # per 100 possessions\n",
    "  'advanced', # advanced\n",
    "    \n",
    "  'playoffs_per_game',\n",
    "  'playoffs_totals',\n",
    "  'playoffs_per_minute', # playoffs per 36 minutes\n",
    "  'playoffs_per_poss', # playoffs per 100 possessions\n",
    "  'playoffs_advanced', \n",
    "    \n",
    "  'all_star',\n",
    "  'all_college_stats',\n",
    "  'all_salaries',\n",
    "]\n",
    "\n",
    "test_names = ['Michael Jordan', 'Vince Carter', 'Yao Ming']\n",
    "test_urls = [\n",
    "    \"https://www.basketball-reference.com/players/m/moncrsi01.html\",\n",
    "    \"https://www.basketball-reference.com/players/b/bellawa01.html\",\n",
    "]\n",
    "\n",
    "# Load list of player (names) \n",
    "# hall_of_famers = load_dict('hall_of_famers.pickle')\n",
    "# retired_all_stars = load_dict('retired_all_stars.pickle')\n",
    "# retired_all_nbas = load_dict('retired_all_nbas.pickle')\n",
    "# players_2015_2016 = load_dict('players_2015_2016.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get URL for a player name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#TODO(jameshu): Add logic to verify the url returned  in fact matches the player name\n",
    "# Currently, even gibberish player_name e.g. \"James Hu\" would have results returned.\n",
    "\n",
    "def get_url_title(url):\n",
    "    page = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    return soup.title.text\n",
    "\n",
    "def get_url(player_name):       \n",
    "    query = (\n",
    "        'site:www.basketball-reference.com/players/*/*.html '\n",
    "        '{player_name} Overview').format(player_name=player_name)\n",
    "    print('query: ', query)\n",
    "\n",
    "    results = google.search(query=query, start=0, stop=1)\n",
    "    urls = list(results)        \n",
    "    \n",
    "    time.sleep(random.randint(5, 10))\n",
    "    \n",
    "    if urls:\n",
    "        return {player_name: urls[0]}\n",
    "    else:\n",
    "        print('url found: None')\n",
    "        return {player_name: None}\n",
    "        \n",
    "print(get_url('Michael Jordan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get URLs for a list of player names, MULTIPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_urls(player_names, num_processes):\n",
    "    p = Pool(processes=num_processes)\n",
    "    outputs = p.map(get_url, player_names)\n",
    "    p.close()\n",
    "    return outputs\n",
    "\n",
    "print(get_urls(test_names[0:2], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET TABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stats table for an url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_table(url):\n",
    "    \n",
    "    output = {}\n",
    "    \n",
    "    page = urllib.request.urlopen(url)\n",
    "    urlHtml = page.read().decode()\n",
    "\n",
    "    # Get the player name\n",
    "    soup = BeautifulSoup(urlHtml, \"html.parser\")\n",
    "    player_name = soup.find(\"h1\").text\n",
    "\n",
    "    # Set the url\n",
    "    output.setdefault(player_name, {}).setdefault('url', url);\n",
    "\n",
    "    # Uncomment the tables\n",
    "    uncommentedUrlHtml = urlHtml.replace('-->', '')\n",
    "    uncommentedUrlHtml = uncommentedUrlHtml.replace('<!--', '')\n",
    "\n",
    "    for table_id in table_ids:\n",
    "        list_of_df = []\n",
    "        try:\n",
    "            list_of_df = pd.read_html(\n",
    "                uncommentedUrlHtml, \n",
    "                header=0, \n",
    "                attrs={'id': table_id})\n",
    "        except ValueError as err:\n",
    "            # Set failures\n",
    "            output.setdefault(player_name, {}).setdefault('failures', {}).update({table_id: str(err)})\n",
    "            continue;\n",
    "\n",
    "        # Drop 'Unnamed' columns\n",
    "        for df in list_of_df:\n",
    "          df.drop([col_name for col_name in df.columns if 'Unnamed' in col_name], axis=1, inplace=True)\n",
    "\n",
    "        # Set table\n",
    "        output.setdefault(player_name, {}).setdefault('tables', {}).update({table_id: list_of_df[0]})\n",
    "\n",
    "    # Print processing info\n",
    "    print(player_name)\n",
    "    print('Tables Found: ', len(output[player_name].get('tables', {})), \n",
    "          ' | Failures: ', output[player_name].get('failures', {}).keys())\n",
    "    print(' ')\n",
    "\n",
    "    return output\n",
    "\n",
    "print(get_table(test_urls[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stats tables for a list of urls, MULTIPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "def get_tables(urls, num_processes):\n",
    "    p = Pool(processes=num_processes)\n",
    "    outputs = p.map(get_table, urls)\n",
    "    p.close()\n",
    "    return outputs\n",
    "\n",
    "len(get_tables(test_urls, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Utility function to merge retrived data tables into 1 dictionary.\n",
    "def merge_dict(list_of_dict):\n",
    "    merged_dict = {}\n",
    "    for dictionary in list_of_dict:\n",
    "        merged_dict.update(dictionary)\n",
    "    return merged_dict\n",
    "\n",
    "# print(merge_dict(test_list).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worksheet = load_worksheet('nba_players_sanitized', 'hof')\n",
    "hof_names = sanitize_list(worksheet[0].tolist())\n",
    "print(hof_names)\n",
    "\n",
    "hof_urls = get_urls(hof_names, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worksheet = load_worksheet('nba_players_sanitized', 'retired_all_stars')\n",
    "retired_all_stars_names = sanitize_list(worksheet[0].tolist())\n",
    "print(retired_all_stars_names)\n",
    "\n",
    "retired_all_stars_urls = get_urls(retired_all_stars_names, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worksheet = load_worksheet('nba_players_sanitized', 'retired_all_nbas')\n",
    "retired_all_nbas_names = sanitize_list(worksheet[0].tolist())\n",
    "print(retired_all_nbas_names)\n",
    "\n",
    "retired_all_nbas_urls = get_urls(retired_all_nbas_names, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worksheet = load_worksheet('nba_players_sanitized', '2015')\n",
    "players_2015_names = sanitize_list(worksheet[0].tolist())\n",
    "print(players_2015_names)\n",
    "\n",
    "players_2015_urls = get_urls(players_2015_names, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dict(hof_urls, 'hof_urls.pickle')\n",
    "save_dict(retired_all_stars_urls, 'retired_all_stars_urls.pickle')\n",
    "save_dict(retired_all_nbas_urls, 'retired_all_nbas_urls.pickle')\n",
    "save_dict(players_2015_urls, 'players_2015_urls.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
